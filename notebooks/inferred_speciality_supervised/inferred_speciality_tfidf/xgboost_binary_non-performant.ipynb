{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_1(X):\n",
    "    X_normalized = []\n",
    "    for i in range(len(X)):\n",
    "        X_normalized.append(np.array(X[i])/sum(X[i]))\n",
    "    return X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(file_name, file_path):\n",
    "    with open(file_path, 'wb') as fp:\n",
    "        pickle.dump(file_name, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(npi_indigo_spl):\n",
    "    npi_indigo_spl_non_nan = {}\n",
    "    for npi in npi_indigo_spl:\n",
    "        if isinstance(npi_indigo_spl[npi], str):\n",
    "            npi_indigo_spl_non_nan[npi] = npi_indigo_spl[npi]\n",
    "    return npi_indigo_spl_non_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(npi_distributions, npi_indigo_spl):\n",
    "    dataset = {'NPI':[], 'features':[], 'labels':[]}\n",
    "    for npi in npi_distributions:\n",
    "        if int(npi) in npi_indigo_spl:\n",
    "            dataset['NPI'].append(npi)\n",
    "            dataset['features'].append(npi_distributions[npi])\n",
    "            dataset['labels'].append(npi_indigo_spl[int(npi)])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_less_than_threshold_categories(y, threshold):\n",
    "    labels_count = {}\n",
    "    for lab in y:\n",
    "        if lab in labels_count:\n",
    "            labels_count[lab] += 1\n",
    "        else:\n",
    "            labels_count[lab] = 1\n",
    "\n",
    "    useless = []\n",
    "    for lab in labels_count:\n",
    "        if labels_count[lab] < threshold:\n",
    "            useless.append(lab)\n",
    "    return useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_useless(useless, y, X):\n",
    "    for i in reversed(range(len(y))):\n",
    "        if y[i] in useless:\n",
    "            del y[i]\n",
    "            del X[i]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def encode_labels(y):\n",
    "#    label_encoder = LabelEncoder()\n",
    "#    return label_encoder.fit_transform(y), label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(y_train):\n",
    "    check = set(y_train)\n",
    "\n",
    "    print('Max value in input: ' +  str(max(check)))\n",
    "    print('\"length-1\" of set of input: ' + str(len(check)-1))\n",
    "    assert max(check) == (len(check)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_from_y(X_train_, y_train_, remove_list):\n",
    "    \n",
    "    X_train_rm = []\n",
    "    y_train_rm = []\n",
    "\n",
    "    for i in range(len(X_train_)):\n",
    "        if y_train_[i] not in remove_list:\n",
    "            X_train_rm.append(X_train_[i])\n",
    "            y_train_rm.append(y_train_[i])\n",
    "    return X_train_rm, y_train_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_distribution(y_train, k):\n",
    "    dataset_distribution = {}\n",
    "    total = 0\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i] not in dataset_distribution:\n",
    "            dataset_distribution[y_train[i]] = 1\n",
    "        else:\n",
    "            dataset_distribution[y_train[i]] += 1\n",
    "        total += 1\n",
    "    \n",
    "    print(dataset_distribution)\n",
    "    remove_list = []\n",
    "    for key in dataset_distribution:\n",
    "        if dataset_distribution[key] < k:\n",
    "            remove_list.append(key)\n",
    "    \n",
    "    print(list(dataset_distribution.values()))\n",
    "    print(max(list(dataset_distribution.values())))\n",
    "    print(min(list(dataset_distribution.values())))\n",
    "    print(np.std(list(dataset_distribution.values())))\n",
    "    return remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels_2way(y):\n",
    "    encoded_y = []\n",
    "    for l in y:\n",
    "        if '-Surgery' in l or '-Minor' in l:\n",
    "            encoded_y.append(0)\n",
    "        else:\n",
    "            encoded_y.append(1)\n",
    "    return encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels_2way_custom(y, label):\n",
    "    encoded_y = []\n",
    "    for l in y:\n",
    "        if label in l:\n",
    "            encoded_y.append(0)\n",
    "        else:\n",
    "            encoded_y.append(1)\n",
    "    return encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overpopulate(X, y, op_multiplier, op_ratio_retained):\n",
    "    X_oped = []\n",
    "    y_oped = []\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            for _ in range(op_multiplier):\n",
    "                X_oped.append(X[i])\n",
    "                y_oped.append(y[i])\n",
    "        elif random.uniform(0, 1) < op_ratio_retained:\n",
    "            X_oped.append(X[i])\n",
    "            y_oped.append(y[i])\n",
    "    \n",
    "    return X_oped, y_oped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_cpts_with_multipliers(normalized_distributions, k):\n",
    "    \n",
    "    all_cpt_pos = {}\n",
    "    for i in range(len(normalized_distributions)):\n",
    "        cur_top_agg = normalized_distributions[i].argsort()[-k:][::-1]\n",
    "        for pos in cur_top_agg:\n",
    "            if pos not in all_cpt_pos:\n",
    "                all_cpt_pos[pos] = 0\n",
    "            all_cpt_pos[pos] += 1\n",
    "                \n",
    "    for cpt_pos in all_cpt_pos:\n",
    "        all_cpt_pos[cpt_pos] = np.log(len(normalized_distributions)/all_cpt_pos[cpt_pos])\n",
    "    \n",
    "    return all_cpt_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_cpts(normalized_distributions, k, tfidf = True):\n",
    "    \n",
    "    all_cpt_pos = {}\n",
    "    print(\"Printing CPT codes with speciality\")\n",
    "    for i in range(len(normalized_distributions)):\n",
    "        cur_top_agg = normalized_distributions[i].argsort()[-k:][::-1]\n",
    "        for pos in cur_top_agg:\n",
    "            if pos not in all_cpt_pos:\n",
    "                all_cpt_pos[pos] = 0\n",
    "            all_cpt_pos[pos] += 1\n",
    "    \n",
    "    single = [code for code in all_cpt_pos if all_cpt_pos[code] == 1]; double = [code for code in all_cpt_pos if all_cpt_pos[code] == 2]\n",
    "    print(single)\n",
    "    print(double)\n",
    "    print(len(double) + len(single))\n",
    "\n",
    "    if tfidf:\n",
    "        for cpt_pos in all_cpt_pos:\n",
    "            all_cpt_pos[cpt_pos] = np.log(len(normalized_distributions)/all_cpt_pos[cpt_pos])\n",
    "\n",
    "        \n",
    "    return all_cpt_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf_vector(all_cpt_pos, num_featurs):\n",
    "    idf_vector = []\n",
    "    for i in range(num_featurs):\n",
    "        if i in all_cpt_pos:\n",
    "            idf_vector.append(all_cpt_pos[i])\n",
    "        else:\n",
    "            idf_vector.append(0)\n",
    "\n",
    "    return idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    for i in range(len(X)):\n",
    "        X[i] = X[i]/sum(X[i])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distributions(X, y):\n",
    "    distributions = [np.array(len(X[0])*[0.0]) for _ in range(len(set(y)))]\n",
    "    for i in range(len(X)):\n",
    "        # if i%10000 == 0:\n",
    "        #     print(\"Done: \" + str(i))\n",
    "        distributions[y[i]] += X[i]\n",
    "    \n",
    "    distributions[1] += distributions[0]\n",
    "    \n",
    "    distributions = normalize(distributions)\n",
    "\n",
    "    return distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(tf_matrix, idf_vector):\n",
    "    tfidfs = []\n",
    "    for tf in tf_matrix:\n",
    "        tfidfs.append(np.multiply(tf, idf_vector[0]))\n",
    "    return tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimention(all_cpt_idfs, X_normalized):\n",
    "    cpt_pos = list(all_cpt_idfs.keys())\n",
    "    #print(cpt_pos)\n",
    "\n",
    "    X_reduced = []\n",
    "\n",
    "    for distribution in X_normalized:\n",
    "        temp = []\n",
    "        for pos in cpt_pos:\n",
    "            if all_cpt_idfs[pos] >= 0.001:\n",
    "                temp.append(distribution[pos])\n",
    "        X_reduced.append(temp)\n",
    "    \n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_features = pd.read_pickle('./chuncked_npi_ncpcs_2019_0_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_indigo_spl = pd.read_pickle('./npi_indigo_spl.pkl')\n",
    "npi_indigo_spl_non_nan = remove_nan(npi_indigo_spl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(npi_features, npi_indigo_spl_non_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['features']\n",
    "y = dataset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153954\n",
      "153954\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Maybe try a binary model of seperating surgical and non-surgical doctors and then create further indigo speciality distinctions for each of these 2 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Create a binary model each indigo speciality (True / False). Kind of a multi-label classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(random_search, results_test, results_train, X_val, y_val, X_train, y_train, spl):\n",
    "    predicted_probabilities = random_search.best_estimator_.predict_proba(X_val)\n",
    "    predictions_test = np.argmax(predicted_probabilities, axis=1)\n",
    "\n",
    "    predicted_probabilities = random_search.best_estimator_.predict_proba(X_train)\n",
    "    predictions_train = np.argmax(predicted_probabilities, axis=1)\n",
    "\n",
    "    test_out = classification_report(y_val, predictions_test, target_names=[spl, 'Others'], output_dict=True)\n",
    "    train_out = classification_report(y_train, predictions_train, target_names=[spl, 'Others'], output_dict=True)\n",
    "\n",
    "    results_train.append([\"CPT upper level features\", \"Train\", spl, train_out['Others']['precision'], train_out['Others']['recall'], train_out[spl]['precision'], train_out[spl]['recall'], train_out['macro avg']['f1-score']])\n",
    "    results_test.append([\"CPT upper level features\", \"Test\", spl, test_out['Others']['precision'], test_out['Others']['recall'], test_out[spl]['precision'], test_out[spl]['recall'], test_out['macro avg']['f1-score']])\n",
    "\n",
    "    return results_train, results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spit_train_test_split(X, y, speciality, param_dist, results_test, results_train, k=25, tfidf=True, majority_class_data_split=0.1, minority_class_op_coef=1, test_size=0.3, random_state=897):\n",
    "    encoded_y = encode_labels_2way_custom(y, speciality)\n",
    "    encoded_y_np = np.array(encoded_y)\n",
    "\n",
    "    if len(encoded_y_np[encoded_y_np==0]) > 0:\n",
    "\n",
    "        X_oped, y_oped = overpopulate(X, encoded_y, minority_class_op_coef, majority_class_data_split)\n",
    "        X_oped_normalized = preprocessing_1(X_oped)\n",
    "\n",
    "        normalized_class_distributions = get_distributions(X_oped_normalized, y_oped)\n",
    "        all_cpt_pos_idf = get_top_k_cpts(normalized_class_distributions, k, tfidf)\n",
    "        idf_vector = get_idf_vector(all_cpt_pos_idf, len(X_oped_normalized[0]))\n",
    "\n",
    "        X_oped_normalized_reduced = reduce_dimention(all_cpt_pos_idf, X_oped_normalized)\n",
    "        # print(np.array(X_oped_normalized_reduced).shape)\n",
    "        idf_vector_reduced = reduce_dimention(all_cpt_pos_idf, [idf_vector])\n",
    "        # print(idf_vector_reduced)\n",
    "\n",
    "        X_oped_normalized_reduced_tfidfs = get_tfidf(X_oped_normalized_reduced, idf_vector_reduced)\n",
    "        X_oped_normalized_reduced_tfidfs = np.array(X_oped_normalized_reduced_tfidfs)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_oped_normalized_reduced_tfidfs, y_oped, test_size=test_size, random_state=random_state, stratify=y_oped, shuffle=True)\n",
    "        # X_train, y_train = overpopulate(X_train, y_train, minority_class_op_coef, 1)\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        print(X_train.shape)\n",
    "        y_train = np.array(y_train)\n",
    "        print(len(y_train[y_train==0]), len(y_train[y_train==1]))\n",
    "        y_val = np.array(y_val)\n",
    "        print(len(y_val[y_val==0]), len(y_val[y_val==1]))\n",
    "\n",
    "        model = xgb.XGBClassifier(objective='multi:softprob', num_class=len(set(y_train)), tree_method='gpu_hist', gpu_id=0)\n",
    "        random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=4, scoring='accuracy', n_jobs=-1, cv=2, verbose=3, random_state=53)\n",
    "        random_search.fit(X_train, y_train)\n",
    "        print(\"Best Estimator: \", random_search.best_params_)\n",
    "        results_train, results_test = get_results(random_search, results_test, results_train, X_val, y_val, X_train, y_train, speciality)\n",
    "        model = None\n",
    "        random_search = None\n",
    "        print('\\033[1m' + '\\033[92m' + \"Done: \" + speciality + '\\033[0m' + '\\033[0m')\n",
    "    else:\n",
    "        print('\\033[1m' + '\\033[91m' + speciality + \" not in CPT upper level features\" + '\\033[0m' + '\\033[0m')\n",
    "    \n",
    "    return results_train, results_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specialities_lis = pd.read_pickle(\"./specialities_lis.pkl\")\n",
    "# specialities_lis = [\"Cardiovascular Disease-Minor Surgery\"]\n",
    "specialities_lis = [\n",
    "    \"Clinical Nurse Specialist\",\n",
    "    \"Certified Nurse Midwife (CNM)\",\n",
    "    \"Anesthesiology Assistant (AA)\",\n",
    "    \"Cardiovascular Disease-Surgery\",\n",
    "    \"Vascular-Surgery\",\n",
    "    \"Dermatology-Minor Surgery\",\n",
    "    \"Neurology-Surgery\",\n",
    "    \"Gynecology-Minor Surgery\",\n",
    "    \"Gynecology-No Surgery\",\n",
    "    \"General Preventive Med-No Surgery\",\n",
    "    \"Orthopedic Incl Back-Surgery\",\n",
    "    \"Ophthalmology-Minor Surgery\",\n",
    "    \"Ophthalmology-Surgery\",\n",
    "    \"Otorhinolaryngology-No Surgery\",\n",
    "    \"Otorhinolaryngology-Surgery\",\n",
    "    \"Radiology Diagnostic-Minor Surgery\",\n",
    "    \"Pediatrics-Minor Surgery\",\n",
    "    \"Aerospace Medicine\",\n",
    "    \"Bariatric-Surgery\",\n",
    "    \"Colon And Rectal-Surgery\",\n",
    "    \"Emergency Medical Technician (EMT)\",\n",
    "    \"Hand-Surgery\",\n",
    "    \"Forensic Medicine\",\n",
    "    \"Geriatrics-No Surgery\",\n",
    "    \"Hand-Surgery\",\n",
    "    \"Nuclear Medicine\",\n",
    "    \"O.R. Technician\",\n",
    "    \"Occupational Medicine\",\n",
    "    \"Pharmacist\",\n",
    "    \"Phlebology\",\n",
    "    \"Physicians NOC-No Surgery\",\n",
    "    \"Physiotherapist\",\n",
    "    \"Plastic Otorhinolaryngology-Surgery\",\n",
    "    \"Respiratory Therapist\",\n",
    "    \"Thoracic-Surgery\",\n",
    "    \"Traumatic-Surgery\",\n",
    "    \"Urgent Care-No Surgery\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing CPT codes with speciality\n",
      "[7461, 7423, 7438, 6284, 11777, 1482, 6283, 6089, 7429, 6081, 15706, 1483, 239, 238, 6075, 14456, 236, 14896, 14460, 12571, 189, 191, 14457, 190]\n",
      "[7393, 7392, 14462, 6073, 6080, 2450, 14461, 407, 2451, 7394, 6074, 12084, 13927]\n",
      "37\n",
      "(11057, 24)\n",
      "192 10865\n",
      "82 4658\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ganga\\anaconda3\\envs\\inferred_speciality\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator:  {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "\u001b[1m\u001b[92mDone: Geriatrics-No Surgery\u001b[0m\u001b[0m\n",
      "Done:  Geriatrics-No Surgery\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Type</td>\n",
       "      <td>Train / Test</td>\n",
       "      <td>Speciality</td>\n",
       "      <td>Precision 0</td>\n",
       "      <td>Recall 0</td>\n",
       "      <td>Precision 1</td>\n",
       "      <td>Recall 1</td>\n",
       "      <td>Macro Avg F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPT upper level features</td>\n",
       "      <td>Test</td>\n",
       "      <td>Geriatrics-No Surgery</td>\n",
       "      <td>0.983305</td>\n",
       "      <td>0.998927</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.52886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Type</td>\n",
       "      <td>Train / Test</td>\n",
       "      <td>Speciality</td>\n",
       "      <td>Precision 0</td>\n",
       "      <td>Recall 0</td>\n",
       "      <td>Precision 1</td>\n",
       "      <td>Recall 1</td>\n",
       "      <td>Macro Avg F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPT upper level features</td>\n",
       "      <td>Train</td>\n",
       "      <td>Geriatrics-No Surgery</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.930896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0             1                      2            3  \\\n",
       "0                 Data Type  Train / Test             Speciality  Precision 0   \n",
       "1  CPT upper level features          Test  Geriatrics-No Surgery     0.983305   \n",
       "2                 Data Type  Train / Test             Speciality  Precision 0   \n",
       "3  CPT upper level features         Train  Geriatrics-No Surgery     0.995784   \n",
       "\n",
       "          4            5         6             7  \n",
       "0  Recall 0  Precision 1  Recall 1  Macro Avg F1  \n",
       "1  0.998927        0.375  0.036585       0.52886  \n",
       "2  Recall 0  Precision 1  Recall 1  Macro Avg F1  \n",
       "3       1.0          1.0  0.760417      0.930896  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 300, 50),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [6, 7, 8, 9],\n",
    "    'colsample_bytree': [0.6, 0.65, 0.7, 0.75],\n",
    "}\n",
    "\n",
    "results_test = [[\"Data Type\", \"Train / Test\", \"Speciality\", \"Precision 0\", \"Recall 0\", \"Precision 1\", \"Recall 1\", \"Macro Avg F1\"]]\n",
    "results_train = [[\"Data Type\", \"Train / Test\", \"Speciality\", \"Precision 0\", \"Recall 0\", \"Precision 1\", \"Recall 1\", \"Macro Avg F1\"]]\n",
    "for spl in specialities_lis:\n",
    "    results_train, results_test = spit_train_test_split(X, y, spl, param_dist, results_test, results_train)\n",
    "    print(\"Done: \", spl)\n",
    "    break\n",
    "\n",
    "df = pd.DataFrame(results_test + results_train)\n",
    "df\n",
    "#df.to_csv('./binary_spl_prediction_tfidf_top25_output_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialities_lis = [\"Occupational Medicine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing CPT codes with speciality\n",
      "[14464, 1493, 14500, 15762, 12574, 9429, 14507, 10228, 3238, 14236, 14238, 14458, 14502, 14463, 14580, 14484, 239, 238, 2450, 6080, 2451, 12084, 236, 7393, 14896, 191, 189, 13927, 12571, 7394, 190, 7392]\n",
      "[14461, 14462, 14456, 6073, 14457, 407, 6075, 14460, 6074]\n",
      "41\n",
      "(5547, 32)\n",
      "188 5359\n",
      "20 2297\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ganga\\anaconda3\\envs\\inferred_speciality\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator:  {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "\u001b[1m\u001b[92mDone: Occupational Medicine\u001b[0m\u001b[0m\n",
      "Done:  Occupational Medicine\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Type</td>\n",
       "      <td>Train / Test</td>\n",
       "      <td>Speciality</td>\n",
       "      <td>Precision 0</td>\n",
       "      <td>Recall 0</td>\n",
       "      <td>Precision 1</td>\n",
       "      <td>Recall 1</td>\n",
       "      <td>Macro Avg F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPT upper level features</td>\n",
       "      <td>Test</td>\n",
       "      <td>Occupational Medicine</td>\n",
       "      <td>0.992211</td>\n",
       "      <td>0.998259</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.574536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Type</td>\n",
       "      <td>Train / Test</td>\n",
       "      <td>Speciality</td>\n",
       "      <td>Precision 0</td>\n",
       "      <td>Recall 0</td>\n",
       "      <td>Precision 1</td>\n",
       "      <td>Recall 1</td>\n",
       "      <td>Macro Avg F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPT upper level features</td>\n",
       "      <td>Train</td>\n",
       "      <td>Occupational Medicine</td>\n",
       "      <td>0.994796</td>\n",
       "      <td>0.998694</td>\n",
       "      <td>0.958084</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.949075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0             1                      2            3  \\\n",
       "0                 Data Type  Train / Test             Speciality  Precision 0   \n",
       "1  CPT upper level features          Test  Occupational Medicine     0.992211   \n",
       "2                 Data Type  Train / Test             Speciality  Precision 0   \n",
       "3  CPT upper level features         Train  Occupational Medicine     0.994796   \n",
       "\n",
       "          4            5         6             7  \n",
       "0  Recall 0  Precision 1  Recall 1  Macro Avg F1  \n",
       "1  0.998259     0.333333       0.1      0.574536  \n",
       "2  Recall 0  Precision 1  Recall 1  Macro Avg F1  \n",
       "3  0.998694     0.958084  0.851064      0.949075  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 300, 50),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [6, 7, 8, 9],\n",
    "    'colsample_bytree': [0.6, 0.65, 0.7, 0.75],\n",
    "}\n",
    "\n",
    "results_test = [[\"Data Type\", \"Train / Test\", \"Speciality\", \"Precision 0\", \"Recall 0\", \"Precision 1\", \"Recall 1\", \"Macro Avg F1\"]]\n",
    "results_train = [[\"Data Type\", \"Train / Test\", \"Speciality\", \"Precision 0\", \"Recall 0\", \"Precision 1\", \"Recall 1\", \"Macro Avg F1\"]]\n",
    "for spl in specialities_lis:\n",
    "    results_train, results_test = spit_train_test_split(X, y, spl, param_dist, results_test, results_train, k=25, tfidf=True, majority_class_data_split=0.05, minority_class_op_coef=4)\n",
    "    print(\"Done: \", spl)\n",
    "\n",
    "df = pd.DataFrame(results_test + results_train)\n",
    "df\n",
    "#df.to_csv('./binary_spl_prediction_tfidf_top25_output_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 300, 50),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [6, 7, 8, 9],\n",
    "    'colsample_bytree': [0.6, 0.65, 0.7, 0.75],\n",
    "}\n",
    "\n",
    "k_range = np.arange(50, 700, 100)\n",
    "runs_per_speciality_per_k = 3\n",
    "\n",
    "results_test = [[\"Data Type\", \"Train / Test\", \"Speciality\", \"Precision 0\", \"Recall 0\", \"Precision 1\", \"Recall 1\", \"Macro Avg F1\"]]\n",
    "results_train = [[\"Data Type\", \"Train / Test\", \"Speciality\", \"Precision 0\", \"Recall 0\", \"Precision 1\", \"Recall 1\", \"Macro Avg F1\"]]\n",
    "for spl in specialities_lis:\n",
    "    for k in range(k_range):\n",
    "        results_train, results_test = spit_train_test_split(X, y, spl, param_dist, results_test, results_train, k=25, tfidf=True, majority_class_data_split=0.05, minority_class_op_coef=4)\n",
    "    print(\"Done: \", spl)\n",
    "\n",
    "df = pd.DataFrame(results_test + results_train)\n",
    "df\n",
    "#df.to_csv('./binary_spl_prediction_tfidf_top25_output_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_codes_2019 = pd.read_pickle(\"./grouped_hcpcs_codes2019.pkl\")\n",
    "singles = [14464, 1493, 14500, 14457, 15762, 12574, 9429, 14507, 14460, 239, 238, 2450, 6080, 2451, 12084, 6074, 7393, 236]\n",
    "singles_code = []\n",
    "doubles = [14461, 14462, 14456, 6073, 407, 6075]\n",
    "doubles_code = []\n",
    "for pos in doubles:\n",
    "    doubles_code.append(cpt_codes_2019[pos])\n",
    "for pos in singles:\n",
    "    singles_code.append(cpt_codes_2019[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['99213', '99214', '99203', '97110', '36415', '97140']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubles_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['99202',\n",
       " 'S9083',\n",
       " '70450',\n",
       " '99204',\n",
       " '93798',\n",
       " '90471',\n",
       " '94010',\n",
       " '73030',\n",
       " '99212',\n",
       " '90837',\n",
       " '90834',\n",
       " '99232',\n",
       " '97530',\n",
       " '99233',\n",
       " '85025',\n",
       " '97112',\n",
       " 'G0299',\n",
       " '90791']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singles_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_codes_2019 = pd.read_pickle(\"./grouped_hcpcs_codes2019.pkl\")\n",
    "singles = [15705, 15714, 15713, 15712, 15703, 15762, 12086, 15755, 15733, 3837, 15715, 10815, 8934, 15753, 2468, 2466, 15758, 2463, 11766, 15711, 15708, 10819, 15735, 15731, 6073, 239, 238, 6075, 6080, 7393, 6074, 236, 13927, 189, 14896, 12571, 191, 190, 237, 7392, 14502, 176, 12574, 244, 7150, 10465, 2437, 10455]\n",
    "singles_code = []\n",
    "doubles = [15706, 14462, 15704, 14461, 2450, 2451, 407, 14457, 7394, 14463, 13929, 12084, 14456, 3446, 2449, 14460]\n",
    "doubles_code = []\n",
    "for pos in doubles:\n",
    "    doubles_code.append(cpt_codes_2019[pos])\n",
    "for pos in singles:\n",
    "    singles_code.append(cpt_codes_2019[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['93010',\n",
       " '99214',\n",
       " '93306',\n",
       " '99213',\n",
       " '99232',\n",
       " '99233',\n",
       " '36415',\n",
       " '99204',\n",
       " 'G0463',\n",
       " '99215',\n",
       " '80048',\n",
       " '85025',\n",
       " '99203',\n",
       " '99223',\n",
       " '99231',\n",
       " '99212']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubles_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['93000',\n",
       " '93325',\n",
       " '93320',\n",
       " '93303',\n",
       " '93005',\n",
       " '93798',\n",
       " '85610',\n",
       " '93321',\n",
       " '93296',\n",
       " '99152',\n",
       " '93458',\n",
       " '99244',\n",
       " '78452',\n",
       " '93304',\n",
       " 'J1644',\n",
       " 'J3010',\n",
       " '93018',\n",
       " 'J2250',\n",
       " 'Q9967',\n",
       " '93017',\n",
       " '93280',\n",
       " '99243',\n",
       " '93299',\n",
       " '93294',\n",
       " '97110',\n",
       " '90837',\n",
       " '90834',\n",
       " '97140',\n",
       " '97530',\n",
       " 'G0299',\n",
       " '97112',\n",
       " '90791',\n",
       " '80053',\n",
       " '99284',\n",
       " '92507',\n",
       " '98941',\n",
       " '99283',\n",
       " '99285',\n",
       " '90832',\n",
       " 'G0151',\n",
       " '71046',\n",
       " '77067',\n",
       " '90471',\n",
       " '90853',\n",
       " '88305',\n",
       " '92014',\n",
       " '99291',\n",
       " '92015']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singles_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['93010', '99214', '99213', '99232', '99233', '36415', '99204', 'G0463']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubles_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['93306',\n",
       " '93000',\n",
       " '93325',\n",
       " '93320',\n",
       " '93303',\n",
       " '93005',\n",
       " '93798',\n",
       " '85610',\n",
       " '99215',\n",
       " '93321',\n",
       " '93296',\n",
       " '80048',\n",
       " '99152',\n",
       " '93458',\n",
       " '99244',\n",
       " '78452',\n",
       " '93304',\n",
       " '97110',\n",
       " '90837',\n",
       " '90834',\n",
       " '97140',\n",
       " '97530',\n",
       " '99203',\n",
       " '85025',\n",
       " '97112',\n",
       " 'G0299',\n",
       " '99212',\n",
       " '90791',\n",
       " '80053',\n",
       " '92507',\n",
       " '99283',\n",
       " '98941',\n",
       " '99284',\n",
       " '99285']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singles_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inferred_speciality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
